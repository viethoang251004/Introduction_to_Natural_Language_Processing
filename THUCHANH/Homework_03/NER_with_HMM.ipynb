{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7asGUxiYh6J",
        "outputId": "5e08205d-b7de-4866-af3a-1268278da0eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.0016000000000000005, ['Person', 'O', 'O', 'Organization'])\n"
          ]
        }
      ],
      "source": [
        "class HMM_NER_Tagger:\n",
        "    def __init__(self, states, observations):\n",
        "        self.states = states  # Named entity labels (e.g., Person, Location, Organization, O)\n",
        "        self.observations = observations  # Words in the vocabulary\n",
        "        self.start_prob = {}\n",
        "        self.transition_prob = {}\n",
        "        self.emission_prob = {}\n",
        "    def train(self, tagged_sentences):\n",
        "        state_count = {state: 0 for state in self.states}\n",
        "        transition_count = {state: {next_state: 0 for next_state in self.states} for state in self.states}\n",
        "        emission_count = {state: {} for state in self.states}  # Dynamic handling of new words\n",
        "\n",
        "        for sentence in tagged_sentences:\n",
        "            prev_state = None\n",
        "            for word, entity in sentence:\n",
        "                state_count[entity] += 1\n",
        "                # Dynamically add new words to emission_count\n",
        "                if word not in emission_count[entity]:\n",
        "                    emission_count[entity][word] = 0\n",
        "                emission_count[entity][word] += 1\n",
        "\n",
        "                if prev_state is None:\n",
        "                    self.start_prob[entity] = self.start_prob.get(entity, 0) + 1\n",
        "                else:\n",
        "                    transition_count[prev_state][entity] += 1\n",
        "\n",
        "                prev_state = entity\n",
        "        # Normalize to get probabilities\n",
        "        total_sentences = len(tagged_sentences)\n",
        "        self.start_prob = {k: v / total_sentences for k, v in self.start_prob.items()}\n",
        "        self.transition_prob = {state: {next_state: transition_count[state][next_state] / state_count[state]\n",
        "                                        for next_state in self.states} for state in self.states}\n",
        "        self.emission_prob = {state: {obs: emission_count[state][obs] / state_count[state]\n",
        "                                      for obs in emission_count[state]} for state in self.states}\n",
        "    def viterbi(self, sentence):\n",
        "        n = len(sentence)\n",
        "        V = [{}]\n",
        "        path = {}\n",
        "\n",
        "        for state in self.states:\n",
        "            V[0][state] = self.start_prob.get(state, 0) * self.emission_prob[state].get(sentence[0], 0)\n",
        "            path[state] = [state]\n",
        "\n",
        "        for t in range(1, n):\n",
        "            V.append({})\n",
        "            new_path = {}\n",
        "\n",
        "            for state in self.states:\n",
        "                (prob, prev_state) = max((V[t-1][y] * self.transition_prob[y][state] * self.emission_prob[state].get(sentence[t], 0), y) for y in self.states)\n",
        "                V[t][state] = prob\n",
        "                new_path[state] = path[prev_state] + [state]\n",
        "\n",
        "            path = new_path\n",
        "\n",
        "        (prob, final_state) = max((V[n-1][state], state) for state in self.states)\n",
        "        return (prob, path[final_state])\n",
        "\n",
        "# Example Usage\n",
        "states = ['Person', 'Location', 'Organization', 'O']\n",
        "observations = ['Alice', 'works', 'in', 'London', 'at', 'Google']  # Initial set of known observations\n",
        "\n",
        "tagger = HMM_NER_Tagger(states, observations)\n",
        "# Training data: list of sentences with (word, Entity label) pairs\n",
        "tagged_sentences = [[('Alice', 'Person'), ('works', 'O'), ('in', 'O'), ('London', 'Location'), ('at', 'O'), ('Google', 'Organization')],\n",
        "                    [('Bob', 'Person'), ('is', 'O'), ('from', 'O'), ('Paris', 'Location')]]  # 'Bob' and 'Paris' not in initial observations\n",
        "\n",
        "tagger.train(tagged_sentences)\n",
        "\n",
        "sentence = ['Alice', 'is', 'in', 'Google']\n",
        "print(tagger.viterbi(sentence))  # Outputs the most probable named entities for the sentence\n"
      ]
    }
  ]
}